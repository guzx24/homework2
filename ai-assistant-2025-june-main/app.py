# import gradio as gr
# import os
# from chat import chat
# from search import search

# # --- Gradio UI å¸ƒå±€ä¸äº‹ä»¶å¤„ç† ---
# with gr.Blocks() as demo:
#     # çŠ¶æ€ç®¡ç†å™¨
#     model_messages = gr.State([])  # æ¨¡å‹å¯¹è¯å†å²ï¼ˆOpenAIæ ¼å¼ï¼‰
#     chat_history = gr.State([])    # UIèŠå¤©å†å²ï¼ˆGradioæ ¼å¼ï¼‰
    
#     # Chatbot UI ç»„ä»¶
#     chatbot = gr.Chatbot(
#         [],
#         elem_id="chatbot",
#         avatar_images=(None, os.path.join(os.path.dirname(__file__), "avatar.png")),
#         height=600,
#         label="AI Assistant"
#     )

#     with gr.Row():
#         txt_input = gr.Textbox(
#             scale=4,
#             show_label=False,
#             placeholder="è¾“å…¥æ–‡å­—æˆ–æŒ‡ä»¤ï¼ˆå¦‚/search å†…å®¹ï¼‰",
#             container=False,
#         )
#         clear_btn = gr.Button('æ¸…ç©º')
#         upload_btn = gr.UploadButton("ğŸ“", file_types=["text"])

#     # --- äº‹ä»¶å¤„ç†å‡½æ•° ---
#     def handle_user_submission(user_input, chat_hist, model_hist):
#         """å¤„ç†ç”¨æˆ·è¾“å…¥ï¼ˆå«ç‰¹æ®ŠæŒ‡ä»¤ï¼‰"""
#         print(f"ç”¨æˆ·è¾“å…¥: {user_input}")
        
#         # å¤„ç†/searchæŒ‡ä»¤
#         if user_input.startswith('/search'):
#             query = user_input[8:].strip()
#             print(f"å¤„ç†æœç´¢æŒ‡ä»¤: {query}")
#             try:
#                 processed_content = search(query)  # è°ƒç”¨æœç´¢å‡½æ•°
#                 print(f"æœç´¢ç»“æœ: {processed_content[:50]}...")
                
#                 # æ›´æ–°æ¨¡å‹å†å²ï¼ˆä½¿ç”¨å¤„ç†åçš„å†…å®¹ï¼‰
#                 model_hist.append({"role": "user", "content": processed_content})
                
#                 # æ›´æ–°UIå†å²ï¼ˆæ˜¾ç¤ºåŸå§‹æŒ‡ä»¤ï¼‰
#                 new_chat_hist = chat_hist + [(f"/search {query}", None)]
#                 return new_chat_hist, model_hist, gr.update(value="", interactive=False)
#             except Exception as e:
#                 print(f"æœç´¢å‡ºé”™: {e}")
#                 error_msg = f"âš ï¸ æœç´¢å¤±è´¥: {str(e)}"
#                 new_chat_hist = chat_hist + [(f"/search {query}", error_msg)]
#                 model_hist.append({"role": "assistant", "content": error_msg})
#                 return new_chat_hist, model_hist, gr.update(value="", interactive=True)
        
#         # æ™®é€šæ¶ˆæ¯
#         model_hist.append({"role": "user", "content": user_input})
#         new_chat_hist = chat_hist + [(user_input, None)]
#         print(f"æ›´æ–°èŠå¤©å†å²: {new_chat_hist}")
#         return new_chat_hist, model_hist, gr.update(value="", interactive=False)

#     def stream_bot_response(chat_hist, model_hist):
#         """æµå¼ç”ŸæˆAIå›å¤"""
#         print(f"å¼€å§‹ç”ŸæˆAIå“åº”, æ¨¡å‹å†å²é•¿åº¦: {len(model_hist)}")
        
#         # åˆ›å»ºä¸´æ—¶å“åº”å ä½ç¬¦
#         chat_hist = chat_hist.copy()  # é¿å…ä¿®æ”¹åŸå§‹çŠ¶æ€
#         if chat_hist and chat_hist[-1][1] is None:
#             chat_hist[-1] = (chat_hist[-1][0], "")
        
#         try:
#             full_response = ""
#             cursor = "â–Œ"  # å…‰æ ‡æŒ‡ç¤ºå™¨
            
#             # è·å–æµå¼å“åº”
#             for chunk in chat(model_hist):
#                 if chunk:
#                     full_response += chunk
#                     # å®æ—¶æ›´æ–°æœ€åä¸€æ¡AIæ¶ˆæ¯
#                     chat_hist[-1] = (chat_hist[-1][0], full_response + cursor)
#                     yield chat_hist
            
#             # æµå¼ç»“æŸï¼šç§»é™¤å…‰æ ‡å¹¶æ›´æ–°çŠ¶æ€
#             chat_hist[-1] = (chat_hist[-1][0], full_response)
#             model_hist.append({"role": "assistant", "content": full_response})
#             print(f"AIå“åº”å®Œæˆ: {full_response[:50]}...")
#             yield chat_hist
            
#         except Exception as e:
#             print(f"ç”Ÿæˆé”™è¯¯: {e}")
#             error_msg = f"âš ï¸ æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ï¼ˆé”™è¯¯ä»£ç ï¼š{str(e)}ï¼‰"
#             chat_hist[-1] = (chat_hist[-1][0], error_msg)
#             model_hist.append({"role": "assistant", "content": error_msg})
#             yield chat_hist

#     def re_enable_textbox():
#         """é‡æ–°æ¿€æ´»è¾“å…¥æ¡†"""
#         print("é‡æ–°æ¿€æ´»è¾“å…¥æ¡†")
#         return gr.update(interactive=True)

#     def clear_chat_history():
#         """æ¸…ç©ºèŠå¤©è®°å½•"""
#         print("æ¸…ç©ºèŠå¤©è®°å½•")
#         return [], []

#     # --- äº‹ä»¶ç»‘å®š ---
#     txt_input.submit(
#         handle_user_submission,
#         [txt_input, chat_history, model_messages],
#         [chat_history, model_messages, txt_input],
#         queue=False
#     ).then(
#         stream_bot_response,
#         [chat_history, model_messages],
#         [chat_history]
#     ).then(
#         re_enable_textbox,
#         None,
#         [txt_input]
#     )

#     clear_btn.click(
#         clear_chat_history,
#         None,
#         [chat_history, model_messages],
#         queue=False
#     )

#     # æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½
#     def add_file_to_ui(chat_hist, file):
#         """å¤„ç†æ–‡ä»¶ä¸Šä¼ """
#         print(f"ä¸Šä¼ æ–‡ä»¶: {file.name}")
#         new_chat_hist = chat_hist + [(f"ğŸ“ å·²ä¸Šä¼ æ–‡ä»¶: {os.path.basename(file.name)}", None)]
#         return new_chat_hist
    
#     upload_btn.upload(
#         add_file_to_ui, 
#         [chat_history, upload_btn], 
#         [chat_history], 
#         queue=False
#     ).then(
#         stream_bot_response,
#         [chat_history, model_messages],
#         [chat_history]
#     )

# demo.queue().launch(debug=True)



import gradio as gr
import os
from chat import chat
# å‡è®¾ search.py å­˜åœ¨ä¸”åŠŸèƒ½æ­£ç¡®
# from search import search # å¦‚æœ search.py æœªå®ç°ï¼Œå¯ä»¥å…ˆæ³¨é‡Šæ‰

# --- Gradio UI å¸ƒå±€ä¸äº‹ä»¶å¤„ç† ---
with gr.Blocks() as demo:
    # çŠ¶æ€ç®¡ç†å™¨ï¼šä½¿ç”¨ gr.State ç‹¬ç«‹ç»´æŠ¤æ¨¡å‹çš„å¯¹è¯å†å²ã€‚
    # è¿™æ˜¯ä¸UIåˆ†ç¦»çš„ã€çœ‹ä¸è§çš„åç«¯çŠ¶æ€ã€‚
    model_messages = gr.State([])

    # Chatbot UI ç»„ä»¶ï¼šä½¿ç”¨ Gradio æ¨èçš„ 'messages' æ ¼å¼ã€‚
    chatbot_ui = gr.Chatbot(
        [],
        elem_id="chatbot",
        avatar_images=(None, os.path.join(os.path.dirname(__file__), "avatar.png")),
        height=600,
        label="AI Assistant",
        type='messages'  # å…³é”®ï¼šåˆ‡æ¢åˆ°æ–°çš„æ¶ˆæ¯æ ¼å¼
    )

    with gr.Row():
        txt_input = gr.Textbox(
            scale=4,
            show_label=False,
            placeholder="è¾“å…¥æ–‡å­—æˆ–æŒ‡ä»¤ï¼ˆå¦‚/search å†…å®¹ï¼‰",
            container=False,
        )
        clear_btn = gr.Button('æ¸…ç©º')
        upload_btn = gr.UploadButton("ğŸ“", file_types=["image", "video", "audio", "text"])

    # --- äº‹ä»¶å¤„ç†å‡½æ•° ---
    def handle_user_submission(user_input, ui_history, model_history):
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥ï¼Œæ›´æ–°UIå’Œåç«¯æ¨¡å‹çŠ¶æ€ã€‚
        """
        # ç®€å•çš„æŒ‡ä»¤å¤„ç†
        # if user_input.startswith('/search'):
        #     query = user_input[8:].strip()
        #     processed_prompt = search(query)
        #     model_history.append({"role": "user", "content": processed_prompt})
        # else:
        model_history.append({"role": "user", "content": user_input})
        
        # æ›´æ–°å‰ç«¯UIçš„çŠ¶æ€
        ui_history.append({"role": "user", "content": user_input})
        
        # è¿”å›æ›´æ–°åçš„çŠ¶æ€ï¼Œå¹¶ç¦ç”¨æ–‡æœ¬æ¡†
        return ui_history, model_history, gr.update(value="", interactive=False)

    def stream_bot_response(ui_history, model_history):
        """
        æµå¼å¤„ç†å¹¶æ˜¾ç¤ºAIçš„å›å¤ã€‚
        """
        # ä¸ºAIçš„å›å¤åœ¨UIä¸Šå‡†å¤‡ä¸€ä¸ªå ä½ç¬¦
        ui_history.append({"role": "assistant", "content": ""})
        
        # ä» chat.py è·å–æµå¼å›å¤
        response_generator = chat(model_history)
        full_response = ""
        
        # è¿­ä»£ç”Ÿæˆå™¨çš„æ¯ä¸ªå—ï¼Œå¹¶æ›´æ–°UI
        for chunk in response_generator:
            full_response += chunk
            ui_history[-1]["content"] = full_response
            yield ui_history
            
        # æµå¼ä¼ è¾“å®Œæˆåï¼Œå°†å®Œæ•´çš„å›å¤æ·»åŠ åˆ°åç«¯æ¨¡å‹çŠ¶æ€ä¸­ä»¥ä¾›è®°å¿†
        model_history.append({"role": "assistant", "content": full_response})

    def re_enable_textbox():
        """é‡æ–°æ¿€æ´»æ–‡æœ¬è¾“å…¥æ¡†ã€‚"""
        return gr.update(interactive=True)

    def clear_chat_history():
        """æ¸…ç©ºåç«¯çŠ¶æ€å’Œå‰ç«¯UIã€‚"""
        return [], []

    # --- äº‹ä»¶ç»‘å®š ---
    txt_input.submit(
        handle_user_submission,
        [txt_input, chatbot_ui, model_messages],
        [chatbot_ui, model_messages, txt_input],
        queue=False
    ).then(
        stream_bot_response,
        [chatbot_ui, model_messages],
        [chatbot_ui]
    ).then(
        re_enable_textbox,
        None,
        [txt_input]
    )

    clear_btn.click(
        clear_chat_history,
        None,
        [chatbot_ui, model_messages],
        queue=False
    )
    
    # æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½ï¼ˆç®€åŒ–ç‰ˆï¼Œå¾…åç»­å®ç°å…·ä½“é€»è¾‘ï¼‰
    def add_file_to_ui(ui_history, file):
        ui_history.append({"role": "user", "content": f"å·²ä¸Šä¼ æ–‡ä»¶: {os.path.basename(file.name)}"})
        ui_history.append({"role": "assistant", "content": "æ–‡ä»¶å·²æ”¶åˆ°ï¼Œè¯·å‘Šè¯‰æˆ‘éœ€è¦å¯¹å®ƒåšä»€ä¹ˆã€‚"})
        return ui_history
    
    upload_btn.upload(add_file_to_ui, [chatbot_ui, upload_btn], [chatbot_ui], queue=False)


demo.queue()
demo.launch()
